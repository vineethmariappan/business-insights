{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d276f4e2-ffde-4f83-9d86-02ae6266acdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2609a0fab41409f80d95eaaf4ef43c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d423bc1ba4a4238968d437de2f349c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/w4/fvh2x8gx6639vy7vkjnqzs1w0000gn/T/ipykernel_4770/375366683.py:59: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>F1 Suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./bert-multiclass-model/tokenizer_config.json',\n",
       " './bert-multiclass-model/special_tokens_map.json',\n",
       " './bert-multiclass-model/vocab.txt',\n",
       " './bert-multiclass-model/added_tokens.json',\n",
       " './bert-multiclass-model/tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train multiclass model for classification\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the dataset\n",
    "df = pd.read_csv(\"sentiment_test_10000_final.csv\")\n",
    "label_map = {\"positive\": 0, \"negative\": 1, \"suggestion\": 2}\n",
    "df[\"label\"] = df[\"label\"].map(label_map)\n",
    "\n",
    "# 2. Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df[[\"text\", \"label\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# 3. Tokenize\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_ds = dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "# 4. Load Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# 5. TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-multiclass-results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# 6. Evaluation Metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    report = classification_report(labels, preds, target_names=list(label_map.keys()), output_dict=True)\n",
    "    return {\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"f1_positive\": report[\"positive\"][\"f1-score\"],\n",
    "        \"f1_negative\": report[\"negative\"][\"f1-score\"],\n",
    "        \"f1_suggestion\": report[\"suggestion\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "# 7. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# 8. Train\n",
    "trainer.train()\n",
    "\n",
    "# 9. Save model\n",
    "trainer.save_model(\"./bert-multiclass-model\")\n",
    "tokenizer.save_pretrained(\"./bert-multiclass-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705eb258-4ffa-47d5-a8a7-ca8d10074204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from minisom import MiniSom  # pip install minisom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df0756a-61d8-4df5-9a2d-df80105cfe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_nlp():\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    nltk.download(\"punkt\")\n",
    "    return nlp\n",
    "\n",
    "def get_reddit_posts():\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"9ETAXWFx9IHiC7AOh8-APg\",\n",
    "        client_secret=\"TuskU4_ysvTwaJJ3i9K40HLEiykE9A\",\n",
    "        user_agent=\"python:brand-sentiment-analyzer:v1.0 (by /u/Soul_Pay4951)\"\n",
    "    )\n",
    "    subreddit = reddit.subreddit(\"technology\")\n",
    "    posts = []\n",
    "    for post in subreddit.hot(limit=500):\n",
    "        post.comments.replace_more(limit=0)  # Removes 'MoreComments'\n",
    "        comments = [comment.body for comment in post.comments.list()]\n",
    "        if len(comments) >= 5:\n",
    "            posts.append((post.title, post.selftext, comments))\n",
    "    return posts\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"\\W\", \" \", text)  # Remove special characters\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"english\")]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def preprocess_for_lda(text, stop_words):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "def extract_entities(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in [\"ORG\", \"PRODUCT\"]]\n",
    "\n",
    "def perform_topic_modeling(tokenized_posts, num_topics=3):\n",
    "    dictionary = corpora.Dictionary(tokenized_posts)\n",
    "    corpus = [dictionary.doc2bow(post) for post in tokenized_posts]\n",
    "    lda_model = LdaMulticore(\n",
    "        corpus,\n",
    "        num_topics=num_topics,\n",
    "        id2word=dictionary,\n",
    "        passes=10,\n",
    "        workers=2\n",
    "    )\n",
    "    topics = lda_model.print_topics(num_words=5)\n",
    "    return topics, lda_model, corpus, dictionary\n",
    "\n",
    "\n",
    "def analyze_multiclass_sentiments(texts):\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = F.softmax(outputs.logits, dim=1)\n",
    "            predicted_class = torch.argmax(probs, dim=1).item()\n",
    "            label = label_map[predicted_class]\n",
    "            score = probs[0][predicted_class].item()\n",
    "            results.append({\"label\": label, \"score\": score})\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6e1e50-ad47-40b1-9815-15fc7bbfd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_suggestions_by_org(cleaned_posts, sentiments, entity_lists):\n",
    "    suggestions_by_org = defaultdict(list)\n",
    "    for (title, body), sentiment, entities in zip(cleaned_posts, sentiments, entity_lists):\n",
    "        if sentiment['label'] == 'suggestion':\n",
    "            text = title + \" \" + body\n",
    "            for entity, ent_type in entities:\n",
    "                if ent_type == \"ORG\":\n",
    "                    suggestions_by_org[entity].append(text)\n",
    "    return suggestions_by_org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8485135-7d48-4b16-a39c-395c1ebdbedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Hebbian Learning simulation: updating an association score for each topic.\n",
    "class HebbianLearning:\n",
    "    def __init__(self, topics):\n",
    "        self.topics = topics\n",
    "        self.associations = {topic: 0.0 for topic in topics}\n",
    "\n",
    "    def update(self, topic, sentiment_score):\n",
    "        learning_rate = 0.1\n",
    "        if topic in self.associations:\n",
    "            self.associations[topic] += learning_rate * sentiment_score\n",
    "\n",
    "    def get_associations(self):\n",
    "        return self.associations\n",
    "\n",
    "# Self-Organizing Maps (SOM) for clustering sentiment trends.\n",
    "def cluster_sentiments(senti_vectors):\n",
    "    if not senti_vectors:\n",
    "        return None\n",
    "    data = np.array(senti_vectors)\n",
    "    # Initialize a SOM with a 3x3 grid.\n",
    "    som = MiniSom(3, 3, data.shape[1], sigma=0.5, learning_rate=0.5, random_seed=42)\n",
    "    som.random_weights_init(data)\n",
    "    som.train_random(data, 100)\n",
    "    # For each sentiment vector, determine its winning node (cluster).\n",
    "    clusters = [som.winner(vec) for vec in data]\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d893b0f8-2568-4532-9f4c-0439eea945f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize SOM\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "def visualize_som_silhouette(senti_vectors, clusters):\n",
    "    if not senti_vectors or not clusters:\n",
    "        print(\"SOM: Insufficient data for silhouette score.\")\n",
    "        return None\n",
    "\n",
    "    data = np.array(senti_vectors)\n",
    "    labels = [f\"{c[0]}-{c[1]}\" for c in clusters]\n",
    "    try:\n",
    "        sil_score = silhouette_score(data, labels)\n",
    "    except:\n",
    "        sil_score = 0\n",
    "\n",
    "    print(f\"SOM Silhouette Score: {sil_score:.4f}\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(['SOM Clustering'], [sil_score], color='darkorange')\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.title(\"SOM Cluster Quality\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return sil_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651bfd0e-3f3d-486e-aedb-05d72c4a00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformers performance\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def visualize_transformer_performance(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    f1_macro = report['macro avg']['f1-score']\n",
    "\n",
    "    print(f\"Transformer Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Transformer F1 Score: {f1_macro:.4f}\")\n",
    "\n",
    "    labels = ['Accuracy', 'F1 Score']\n",
    "    values = [accuracy, f1_macro]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(labels, values, color='mediumseagreen')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"Transformer Performance\")\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return accuracy, f1_macro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea4238d5-460c-4fd7-b9fe-8e9bdf9c1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_method_comparison(lda_score, som_score, transformer_score):\n",
    "    methods = ['LDA', 'SOM', 'Transformer']\n",
    "    scores = [lda_score, som_score, transformer_score]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(methods, scores, color=['cornflowerblue', 'darkorange', 'mediumseagreen'])\n",
    "    plt.ylabel('Evaluation Metric (Scaled 0-1)')\n",
    "    plt.title('Method Comparison: Insight Value / Quality Metric')\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f\"{yval:.2f}\", ha='center')\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6440350f-8f05-45eb-9621-42ba21e62319",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_nlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m posts \u001b[38;5;241m=\u001b[39m get_reddit_posts()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Clean posts (title and selftext)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m, in \u001b[0;36minitialize_nlp\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_nlp\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstopwords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.10/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.10/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "#Execute\n",
    "\n",
    "nlp = initialize_nlp()\n",
    "posts = get_reddit_posts()\n",
    "\n",
    "# Clean posts (title and selftext)\n",
    "cleaned_posts = [(clean_text(title), clean_text(body)) for title, body, _ in posts]\n",
    "print(\"Cleaned Posts:\")\n",
    "for cp in cleaned_posts:\n",
    "    print(cp)\n",
    "\n",
    "# Extract entities (e.g., brands, products) using NER\n",
    "brands_products = [extract_entities(title + \" \" + body, nlp) for title, body in cleaned_posts]\n",
    "print(\"\\nExtracted Entities (Brands/Products):\")\n",
    "for bp in brands_products:\n",
    "    print(bp)\n",
    "\n",
    "# Preprocess text for LDA topic modeling\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tokenized_posts = [preprocess_for_lda(title + \" \" + body, stop_words) for title, body in cleaned_posts]\n",
    "topics, lda_model, corpus, dictionary = perform_topic_modeling(tokenized_posts, num_topics=3)\n",
    "print(\"\\nTopics from LDA:\")\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "# --- Sentiment Analysis ---\n",
    "combined_texts = [title + \" \" + body for title, body in cleaned_posts]\n",
    "sentiments = analyze_multiclass_sentiments(combined_texts)\n",
    "print(\"\\nMulticlass Sentiments:\")\n",
    "for sentiment in sentiments:\n",
    "    print(sentiment)\n",
    "\n",
    "# --- Hebbian Learning ---\n",
    "topic_strs = [t[1] for t in topics]\n",
    "hebbian = HebbianLearning(topic_strs)\n",
    "for res in sentiments:\n",
    "    score = res['score'] if res['label'] == \"positive\" else -res['score']\n",
    "    for topic in topic_strs:\n",
    "        hebbian.update(topic, score)\n",
    "associations = hebbian.get_associations()\n",
    "print(\"\\nHebbian Associations:\")\n",
    "for topic, assoc in associations.items():\n",
    "    print(f\"{topic}: {assoc:.4f}\")\n",
    "\n",
    "# --- SOM Sentiment Vectors (3-class) ---\n",
    "senti_vectors = []\n",
    "for res in sentiments:\n",
    "    if res['label'] == \"positive\":\n",
    "        senti_vectors.append([res['score'], 0.0, 0.0])\n",
    "    elif res['label'] == \"negative\":\n",
    "        senti_vectors.append([0.0, res['score'], 0.0])\n",
    "    else:  # suggestion\n",
    "        senti_vectors.append([0.0, 0.0, res['score']])\n",
    "clusters = cluster_sentiments(senti_vectors)\n",
    "print(\"\\nSOM Clusters:\")\n",
    "print(clusters)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf04f4a6-ef06-4d79-a55d-8b4f8b10159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize suggestions\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def summarize_suggestions(suggestions_by_org, num_summary_sentences=3):\n",
    "    summary_by_org = {}\n",
    "\n",
    "    for org, suggestions in suggestions_by_org.items():\n",
    "        if not suggestions:\n",
    "            continue\n",
    "\n",
    "        # Clean and preprocess suggestions\n",
    "        clean_suggestions = [re.sub(r'\\s+', ' ', s.strip()) for s in suggestions]\n",
    "\n",
    "        # Vectorize\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        X = vectorizer.fit_transform(clean_suggestions)\n",
    "\n",
    "        # Cluster into a few themes\n",
    "        n_clusters = min(3, len(clean_suggestions))\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(X)\n",
    "\n",
    "        # Find representative suggestion from each cluster\n",
    "        summary = []\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = (kmeans.labels_ == i).nonzero()[0]\n",
    "            if len(cluster_indices) > 0:\n",
    "                first_comment = clean_suggestions[cluster_indices[0]]\n",
    "                summary.append(first_comment)\n",
    "\n",
    "        summary_by_org[org] = summary[:num_summary_sentences]\n",
    "\n",
    "    return summary_by_org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4bbc861-cb31-4eec-8c0f-6e0576fdb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_lda_coherence(lda_model, tokenized_posts, dictionary):\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=tokenized_posts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print(f\"LDA Coherence Score: {coherence_score:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(['LDA Topic Modeling'], [coherence_score], color='cornflowerblue')\n",
    "    plt.ylabel(\"Coherence Score (c_v)\")\n",
    "    plt.title(\"LDA Coherence Score\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return coherence_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "700d3600-6223-485b-89a4-ee6c8f62312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Suggestions by Organization:\n",
      "{}\n",
      "\n",
      "Summary of Suggestions by Organization:\n"
     ]
    }
   ],
   "source": [
    "# --- Suggestions Per Organization ---\n",
    "suggestions_by_org = get_suggestions_by_org(cleaned_posts, sentiments, brands_products)\n",
    "print(\"\\nSuggestions by Organization:\")\n",
    "for org, suggestions in suggestions_by_org.items():\n",
    "    print(f\"\\n{org}:\")\n",
    "    for s in suggestions:\n",
    "        print(f\"  - {s}\")\n",
    "        \n",
    "summarized = summarize_suggestions(suggestions_by_org)\n",
    "print(summarized)\n",
    "print(\"\\nSummary of Suggestions by Organization:\")\n",
    "for org, summaries in summarized.items():\n",
    "    print(f\"\\n{org}:\")\n",
    "    for s in summaries:\n",
    "        print(f\"  - {s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00f5ea09-8797-4572-91a8-c552c0129bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions_by_org = get_suggestions_by_org(cleaned_posts, sentiments, brands_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b73335-278e-47de-a9a6-43782372755d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load your trained model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m sentiment_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbert-multiclass-model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbert-multiclass-model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_sentiments\u001b[39m(texts):\n\u001b[1;32m      7\u001b[0m     sentiments \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.10/site-packages/transformers/pipelines/__init__.py:942\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 942\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    953\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.10/site-packages/transformers/pipelines/base.py:242\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    248\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[0;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load your trained model\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"./bert-multiclass-model\", tokenizer=\"./bert-multiclass-model\")\n",
    "\n",
    "def analyze_sentiments(texts):\n",
    "    sentiments = []\n",
    "    for text in texts:\n",
    "        result = sentiment_pipeline(text)[0]  # e.g., {'label': 'LABEL_2', 'score': 0.92}\n",
    "        label = result['label']\n",
    "        label_map = {'LABEL_0': 'POSITIVE', 'LABEL_1': 'NEGATIVE', 'LABEL_2': 'SUGGESTION'}\n",
    "        sentiments.append({'label': label_map[label], 'score': result['score']})\n",
    "    return sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667eb38-ee9d-41a1-a1fa-cb47dc4156fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_score = visualize_lda_coherence(lda_model, tokenized_posts, dictionary)\n",
    "som_score = visualize_som_silhouette(senti_vectors, clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b36915-d849-4f5a-ac42-97cd674b969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load test data\n",
    "df = pd.read_csv(\"sentiment_test_10000_final.csv\")\n",
    "texts = df[\"text\"].tolist()\n",
    "y_true = df[\"label\"].tolist()\n",
    "\n",
    "# Predict using transformer model\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "y_pred = []\n",
    "\n",
    "for text in texts:\n",
    "    result = sentiment_pipeline(text)[0][\"label\"].lower()\n",
    "    if result == \"positive\":\n",
    "        y_pred.append(\"positive\")\n",
    "    else:\n",
    "        y_pred.append(\"negative\")  # or \"suggestion\" if you're handling that\n",
    "\n",
    "# Now call the visualization\n",
    "transformer_accuracy, transformer_f1 = visualize_transformer_performance(y_true, y_pred)\n",
    "\n",
    "visualize_method_comparison(lda_score, som_score, transformer_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
