{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d276f4e2-ffde-4f83-9d86-02ae6266acdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf732c20dceb4a4599dc97d37bd8090b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4020 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e4d09b1e5f4eec9d1a0bdee79d5b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1006 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/w4/fvh2x8gx6639vy7vkjnqzs1w0000gn/T/ipykernel_1633/844038094.py:59: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6/756 00:02 < 08:45, 1.43 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train multiclass model for classification\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the dataset\n",
    "df = pd.read_csv(\"reddit_sentiment_labeled_5000.csv\")\n",
    "label_map = {\"Positive\": 0, \"Negative\": 1, \"Suggestion\": 2, \"Neutral\": 3}\n",
    "df[\"label\"] = df[\"label\"].map(label_map)\n",
    "\n",
    "# 2. Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df[[\"text\", \"label\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# 3. Tokenize\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_ds = dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "# 4. Load Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# 5. TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-multiclass-results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# 6. Evaluation Metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    report = classification_report(labels, preds, target_names=list(label_map.keys()), output_dict=True)\n",
    "    return {\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"f1_positive\": report[\"Positive\"][\"f1-score\"],\n",
    "        \"f1_negative\": report[\"Negative\"][\"f1-score\"],\n",
    "        \"f1_suggestion\": report[\"Suggestion\"][\"f1-score\"],\n",
    "        \"f1_neutral\": report[\"Neutral\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "# 7. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# 8. Train\n",
    "trainer.train()\n",
    "\n",
    "# 9. Save model\n",
    "trainer.save_model(\"./bert-multiclass-model\")\n",
    "tokenizer.save_pretrained(\"./bert-multiclass-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705eb258-4ffa-47d5-a8a7-ca8d10074204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from minisom import MiniSom  # pip install minisom\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df0756a-61d8-4df5-9a2d-df80105cfe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_nlp():\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    nltk.download(\"punkt\")\n",
    "    return nlp\n",
    "\n",
    "def clean_lda_keywords_with_pos(topic_terms):\n",
    "    raw_keywords = [kw.split(\"*\")[1].replace('\"', '').strip() for kw in topic_terms.split(\"+\")]\n",
    "    doc = nlp(\" \".join(raw_keywords))\n",
    "    allowed_pos = {\"NOUN\", \"PROPN\", \"ADJ\"}  # nouns, adjectives\n",
    "    filtered = [token.text for token in doc if token.pos_ in allowed_pos]\n",
    "    return filtered[:5]\n",
    "\n",
    "def get_reddit_posts(cache_path=\"reddit_buyitforlife_posts.csv\"):\n",
    "    if os.path.exists(cache_path):\n",
    "        print(\" Loading posts from cached CSV...\")\n",
    "        df = pd.read_csv(cache_path)\n",
    "        posts = list(zip(df[\"title\"], df[\"body\"]))\n",
    "    else:\n",
    "        print(\" Fetching posts from Reddit API...\")\n",
    "        reddit = praw.Reddit(\n",
    "            client_id=\"9ETAXWFx9IHiC7AOh8-APg\",\n",
    "            client_secret=\"TuskU4_ysvTwaJJ3i9K40HLEiykE9A\",\n",
    "            user_agent=\"python:brand-sentiment-analyzer:v1.0 (by /u/Soul_Pay4951)\"\n",
    "        )\n",
    "        subreddit = reddit.subreddit(\"buyitforlife\")\n",
    "        posts = []\n",
    "        for post in subreddit.hot(limit=300):\n",
    "            post.comments.replace_more(limit=0)\n",
    "            comments = [comment.body for comment in post.comments.list()]\n",
    "            top_comments = \" \".join(comments[:3])  # optional\n",
    "            title = post.title.strip()\n",
    "            body = (post.selftext + \" \" + top_comments).strip()\n",
    "            posts.append((title, body))\n",
    "\n",
    "        # Save to CSV\n",
    "        df = pd.DataFrame(posts, columns=[\"title\", \"body\"])\n",
    "        df.to_csv(cache_path, index=False)\n",
    "        print(f\" Saved {len(posts)} posts to {cache_path}\")\n",
    "\n",
    "    return posts\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"\\W\", \" \", text)  # Remove special characters\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"english\")]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def preprocess_for_lda(text, stop_words):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "def extract_entities(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"ORG\", \"PRODUCT\"]:\n",
    "            name = ent.text.strip()\n",
    "\n",
    "            # Filter out long or messy names\n",
    "            if len(name.split()) > 3:\n",
    "                continue\n",
    "            if any(word.lower() in stopwords.words(\"english\") for word in name.split()):\n",
    "                continue\n",
    "            if name.isdigit():\n",
    "                continue\n",
    "\n",
    "            # Normalize casing\n",
    "            name = name.title()\n",
    "\n",
    "            entities.append((name, ent.label_))\n",
    "    return entities\n",
    "\n",
    "\n",
    "def perform_topic_modeling(tokenized_posts, num_topics=3):\n",
    "    dictionary = corpora.Dictionary(tokenized_posts)\n",
    "    corpus = [dictionary.doc2bow(post) for post in tokenized_posts]\n",
    "    lda_model = LdaMulticore(\n",
    "        corpus,\n",
    "        num_topics=num_topics,\n",
    "        id2word=dictionary,\n",
    "        passes=10,\n",
    "        workers=2\n",
    "    )\n",
    "    topics = lda_model.print_topics(num_words=5)\n",
    "    return topics, lda_model, corpus, dictionary\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# load pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./bert-multiclass-model\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./bert-multiclass-model\")\n",
    "\n",
    "# Make sure this matches your model's class mapping\n",
    "label_map = {\n",
    "    0: \"POSITIVE\",\n",
    "    1: \"NEGATIVE\",\n",
    "    2: \"SUGGESTION\"\n",
    "}\n",
    "\n",
    "def analyze_multiclass_sentiments(texts):\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = F.softmax(outputs.logits, dim=1)\n",
    "        predicted_class = torch.argmax(probs, dim=1).item()\n",
    "        label = label_map[predicted_class]\n",
    "        score = probs[0][predicted_class].item()\n",
    "        results.append({\"label\": label, \"score\": round(score, 4)})\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6e1e50-ad47-40b1-9815-15fc7bbfd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from difflib import get_close_matches\n",
    "\n",
    "valid_brands = {\"ikea\"}\n",
    "\n",
    "\n",
    "def resolve_to_known_brand(entity_text):\n",
    "    entity_clean = re.sub(r'[^a-z0-9\\s]', '', entity_text.lower().strip())\n",
    "    tokens = entity_clean.split()\n",
    "    for word in tokens:\n",
    "        if word in valid_brands:\n",
    "            return word\n",
    "    match = get_close_matches(entity_clean, valid_brands, n=1, cutoff=0.85)\n",
    "    return match[0] if match else None\n",
    "\n",
    "def get_suggestions_by_org(cleaned_posts, sentiments, entity_lists):\n",
    "    suggestions_by_org = defaultdict(list)\n",
    "    for (title, body), sentiment, entities in zip(cleaned_posts, sentiments, entity_lists):\n",
    "        if sentiment['label'] == 'SUGGESTION' and sentiment['score'] > 0.85:\n",
    "            text = title + \" \" + body\n",
    "            for entity, ent_type in entities:\n",
    "                if ent_type == \"ORG\":\n",
    "                    resolved = resolve_to_known_brand(entity)\n",
    "                    if resolved:\n",
    "                        suggestions_by_org[resolved].append(text)\n",
    "    return suggestions_by_org\n",
    "\n",
    "def compute_sentiment_breakdown_per_org(cleaned_posts, sentiments, entity_lists):\n",
    "    org_sentiment_count = defaultdict(lambda: {\"POSITIVE\": 0, \"NEGATIVE\": 0, \"SUGGESTION\": 0})\n",
    "    for (title, body), sentiment, entities in zip(cleaned_posts, sentiments, entity_lists):\n",
    "        for entity, ent_type in entities:\n",
    "            if ent_type == \"ORG\":\n",
    "                org_sentiment_count[entity][sentiment['label']] += 1\n",
    "    return org_sentiment_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8485135-7d48-4b16-a39c-395c1ebdbedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Hebbian Learning simulation: updating an association score for each topic.\n",
    "class HebbianLearning:\n",
    "    def __init__(self, topics):\n",
    "        self.topics = topics\n",
    "        self.associations = {topic: 0.0 for topic in topics}\n",
    "\n",
    "    def update(self, topic, sentiment_score):\n",
    "        learning_rate = 0.1\n",
    "        if topic in self.associations:\n",
    "            self.associations[topic] += learning_rate * sentiment_score\n",
    "\n",
    "    def get_associations(self):\n",
    "        return self.associations\n",
    "\n",
    "# Self-Organizing Maps (SOM) for clustering sentiment trends.\n",
    "def cluster_sentiments(senti_vectors):\n",
    "    if not senti_vectors:\n",
    "        return None\n",
    "    data = np.array(senti_vectors)\n",
    "    # Initialize a SOM with a 3x3 grid.\n",
    "    som = MiniSom(3, 3, data.shape[1], sigma=0.5, learning_rate=0.5, random_seed=42)\n",
    "    som.random_weights_init(data)\n",
    "    som.train_random(data, 100)\n",
    "    # For each sentiment vector, determine its winning node (cluster).\n",
    "    clusters = [som.winner(vec) for vec in data]\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d893b0f8-2568-4532-9f4c-0439eea945f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize SOM\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "def visualize_som_silhouette(senti_vectors, clusters):\n",
    "    if not senti_vectors or not clusters:\n",
    "        print(\"SOM: Insufficient data for silhouette score.\")\n",
    "        return None\n",
    "\n",
    "    data = np.array(senti_vectors)\n",
    "    labels = [f\"{c[0]}-{c[1]}\" for c in clusters]\n",
    "    try:\n",
    "        sil_score = silhouette_score(data, labels)\n",
    "    except:\n",
    "        sil_score = 0\n",
    "\n",
    "    print(f\"SOM Silhouette Score: {sil_score:.4f}\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(['SOM Clustering'], [sil_score], color='darkorange')\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.title(\"SOM Cluster Quality\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return sil_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651bfd0e-3f3d-486e-aedb-05d72c4a00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformers performance\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def visualize_transformer_performance(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    f1_macro = report['macro avg']['f1-score']\n",
    "\n",
    "    print(f\"Transformer Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Transformer F1 Score: {f1_macro:.4f}\")\n",
    "\n",
    "    labels = ['Accuracy', 'F1 Score']\n",
    "    values = [accuracy, f1_macro]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(labels, values, color='mediumseagreen')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"Transformer Performance\")\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return accuracy, f1_macro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4238d5-460c-4fd7-b9fe-8e9bdf9c1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_method_comparison(lda_score, som_score, transformer_score):\n",
    "    methods = ['LDA', 'SOM', 'Transformer']\n",
    "    scores = [lda_score, som_score, transformer_score]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(methods, scores, color=['cornflowerblue', 'darkorange', 'mediumseagreen'])\n",
    "    plt.ylabel('Evaluation Metric (Scaled 0-1)')\n",
    "    plt.title('Method Comparison: Insight Value / Quality Metric')\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f\"{yval:.2f}\", ha='center')\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6440350f-8f05-45eb-9621-42ba21e62319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vineethmariappan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vineethmariappan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading posts from cached CSV...\n",
      "\n",
      "Multiclass Sentiments:\n",
      "{'label': 'NEGATIVE', 'score': 0.7107}\n",
      "{'label': 'NEGATIVE', 'score': 0.6751}\n",
      "{'label': 'NEGATIVE', 'score': 0.9644}\n",
      "{'label': 'NEGATIVE', 'score': 0.6361}\n",
      "{'label': 'SUGGESTION', 'score': 0.6025}\n",
      "{'label': 'POSITIVE', 'score': 0.923}\n",
      "{'label': 'SUGGESTION', 'score': 0.9854}\n",
      "{'label': 'POSITIVE', 'score': 0.9422}\n",
      "{'label': 'NEGATIVE', 'score': 0.9746}\n",
      "{'label': 'SUGGESTION', 'score': 0.8965}\n",
      "{'label': 'SUGGESTION', 'score': 0.992}\n",
      "{'label': 'POSITIVE', 'score': 0.7665}\n",
      "{'label': 'NEGATIVE', 'score': 0.5361}\n",
      "{'label': 'SUGGESTION', 'score': 0.9924}\n",
      "{'label': 'SUGGESTION', 'score': 0.8976}\n",
      "{'label': 'SUGGESTION', 'score': 0.9918}\n",
      "{'label': 'NEGATIVE', 'score': 0.5155}\n",
      "{'label': 'NEGATIVE', 'score': 0.9319}\n",
      "{'label': 'SUGGESTION', 'score': 0.9936}\n",
      "{'label': 'SUGGESTION', 'score': 0.7626}\n",
      "{'label': 'SUGGESTION', 'score': 0.9823}\n",
      "{'label': 'SUGGESTION', 'score': 0.9876}\n",
      "{'label': 'SUGGESTION', 'score': 0.9083}\n",
      "{'label': 'SUGGESTION', 'score': 0.9562}\n",
      "{'label': 'SUGGESTION', 'score': 0.5712}\n",
      "{'label': 'SUGGESTION', 'score': 0.7876}\n",
      "{'label': 'SUGGESTION', 'score': 0.9709}\n",
      "{'label': 'POSITIVE', 'score': 0.5779}\n",
      "{'label': 'POSITIVE', 'score': 0.8638}\n",
      "{'label': 'NEGATIVE', 'score': 0.984}\n",
      "{'label': 'POSITIVE', 'score': 0.9769}\n",
      "{'label': 'NEGATIVE', 'score': 0.9753}\n",
      "{'label': 'NEGATIVE', 'score': 0.9919}\n",
      "{'label': 'POSITIVE', 'score': 0.6899}\n",
      "{'label': 'NEGATIVE', 'score': 0.9566}\n",
      "{'label': 'NEGATIVE', 'score': 0.6757}\n",
      "{'label': 'POSITIVE', 'score': 0.9896}\n",
      "{'label': 'SUGGESTION', 'score': 0.6224}\n",
      "{'label': 'SUGGESTION', 'score': 0.6329}\n",
      "{'label': 'NEGATIVE', 'score': 0.9274}\n",
      "{'label': 'NEGATIVE', 'score': 0.9816}\n",
      "{'label': 'SUGGESTION', 'score': 0.8799}\n",
      "{'label': 'SUGGESTION', 'score': 0.8254}\n",
      "{'label': 'SUGGESTION', 'score': 0.6447}\n",
      "{'label': 'POSITIVE', 'score': 0.9905}\n",
      "{'label': 'POSITIVE', 'score': 0.9885}\n",
      "{'label': 'SUGGESTION', 'score': 0.9036}\n",
      "{'label': 'SUGGESTION', 'score': 0.7652}\n",
      "{'label': 'SUGGESTION', 'score': 0.8022}\n",
      "{'label': 'NEGATIVE', 'score': 0.7739}\n",
      "\n",
      "Extracted Entities (Brands/Products):\n",
      "[('Buyitforlife Canada', 'ORG')]\n",
      "[('Lennon Uk', 'ORG'), ('Cookware Solidteknics Aus', 'ORG')]\n",
      "[]\n",
      "[]\n",
      "[('Tempur', 'ORG')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[('Recs Mobile', 'ORG'), ('Arena Speedo', 'ORG')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[('Cole', 'PRODUCT')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[('Atlantis', 'PRODUCT'), ('Demeyre De Buyer', 'ORG')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[('Slip Steel', 'ORG')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics from LDA:\n",
      "(0, '0.016*\"leather\" + 0.010*\"quality\" + 0.007*\"one\" + 0.007*\"used\" + 0.006*\"buy\"')\n",
      "(1, '0.007*\"good\" + 0.007*\"years\" + 0.007*\"like\" + 0.006*\"one\" + 0.006*\"looking\"')\n",
      "(2, '0.008*\"like\" + 0.008*\"one\" + 0.007*\"looking\" + 0.007*\"water\" + 0.006*\"work\"')\n",
      "[{'topic_id': 0, 'keywords': ['leather', 'quality', 'buy'], 'insight': 'ðŸ’¡ Users are sharing a lot of suggestions here.', 'positive': 1, 'negative': 9, 'suggestion': 11, 'example_posts': ['A list of BIFL not made in the USA A timely reminder that this subreddit is obviously very USA centric with its recommendations as that s where the majority of users are from.', \"The Fairphone 5 price has been dropped to 499 and promises support till 2031 Maybe i missed it, but where do they say what 'supported till 2031'?\"]}, {'topic_id': 1, 'keywords': ['good', 'years'], 'insight': 'âœ… This topic is receiving mostly positive feedback.', 'positive': 7, 'negative': 4, 'suggestion': 4, 'example_posts': ['40 years old Alessi Mocha Maker 40 years ago, my parents used this Alessi moka pot to make coffee on camping trips in the south of France.', 'I bought this knife 12 years ago, I carry and use it everyday.']}, {'topic_id': 2, 'keywords': ['water', 'work'], 'insight': 'ðŸ’¡ Users are sharing a lot of suggestions here.', 'positive': 2, 'negative': 3, 'suggestion': 9, 'example_posts': ['High quality made in Canada pots and pans, I have their non stick 12 .', 'Been eyeing the Coop Eden Pillow and the Tempur Cloud Breeze Dual Cooling, but I haven t committed yet.']}]\n",
      "\n",
      "Hebbian Associations:\n",
      "0.016*\"leather\" + 0.010*\"quality\" + 0.007*\"one\" + 0.007*\"used\" + 0.006*\"buy\": -4.2274\n",
      "0.007*\"good\" + 0.007*\"years\" + 0.007*\"like\" + 0.006*\"one\" + 0.006*\"looking\": -4.2274\n",
      "0.008*\"like\" + 0.008*\"one\" + 0.007*\"looking\" + 0.007*\"water\" + 0.006*\"work\": -4.2274\n",
      "\n",
      "SOM Clusters:\n",
      "[(2, 1), (2, 1), (0, 0), (2, 1), (2, 2), (1, 1), (0, 1), (1, 1), (1, 0), (2, 0), (0, 1), (1, 2), (2, 2), (0, 1), (2, 0), (0, 1), (2, 2), (1, 1), (0, 1), (1, 2), (1, 0), (0, 1), (2, 0), (0, 2), (2, 2), (1, 2), (0, 0), (2, 2), (2, 0), (1, 0), (1, 0), (1, 0), (0, 1), (2, 1), (0, 2), (2, 1), (0, 1), (2, 1), (2, 1), (1, 1), (1, 0), (2, 0), (1, 2), (2, 1), (0, 1), (0, 1), (2, 0), (1, 2), (1, 2), (1, 2)]\n"
     ]
    }
   ],
   "source": [
    "# 1. Load & Clean Data\n",
    "nlp = initialize_nlp()\n",
    "posts = get_reddit_posts()\n",
    "cleaned_posts = [(clean_text(title), clean_text(body)) for title, body in posts]\n",
    "original_texts = [title + \" \" + body for title, body in posts]  # Uncleaned\n",
    "tokenized_posts = [preprocess_for_lda(title + \" \" + body, stop_words) for title, body in cleaned_posts]\n",
    "\n",
    "combined_texts = [title + \" \" + body for title, body in cleaned_posts]\n",
    "\n",
    "# 2. Sentiment Analysis\n",
    "sentiments = analyze_multiclass_sentiments(original_texts)\n",
    "print(\"\\nMulticlass Sentiments:\")\n",
    "for sentiment in sentiments:\n",
    "    print(sentiment)\n",
    "\n",
    "# 3. Entity Extraction (Brands/Products)\n",
    "brands_products = [extract_entities(text, nlp) for text in combined_texts]\n",
    "print(\"\\nExtracted Entities (Brands/Products):\")\n",
    "for bp in brands_products:\n",
    "    print(bp)\n",
    "\n",
    "# 4. LDA Topic Modeling\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tokenized_posts = [preprocess_for_lda(text, stop_words) for text in combined_texts]\n",
    "topics, lda_model, corpus, dictionary = perform_topic_modeling(tokenized_posts, num_topics=12)\n",
    "print(\"\\nTopics from LDA:\")\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "# 5. Assign Topics and Compute Sentiment Counts per Topic\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_topic_sentiment_counts(lda_model, corpus, sentiments):\n",
    "    topic_sentiment_counts = defaultdict(lambda: {\"POSITIVE\": 0, \"NEGATIVE\": 0, \"SUGGESTION\": 0})\n",
    "    for i, bow in enumerate(corpus):\n",
    "        topic_distribution = lda_model.get_document_topics(bow)\n",
    "        if topic_distribution:\n",
    "            dominant_topic = max(topic_distribution, key=lambda x: x[1])[0]\n",
    "            sentiment_label = sentiments[i][\"label\"]\n",
    "            topic_sentiment_counts[dominant_topic][sentiment_label] += 1\n",
    "    return topic_sentiment_counts\n",
    "\n",
    "def assign_posts_to_lda_topics(lda_model, corpus, original_texts):\n",
    "    topic_to_posts = defaultdict(list)\n",
    "    for i, bow in enumerate(corpus):\n",
    "        topic_distribution = lda_model.get_document_topics(bow)\n",
    "        if topic_distribution:\n",
    "            dominant_topic = max(topic_distribution, key=lambda x: x[1])[0]\n",
    "            topic_to_posts[dominant_topic].append(original_texts[i])\n",
    "    return topic_to_posts\n",
    "\n",
    "topic_sentiment_counts = compute_topic_sentiment_counts(lda_model, corpus, sentiments)\n",
    "topic_to_posts = assign_posts_to_lda_topics(lda_model, corpus, original_texts)\n",
    "\n",
    "\n",
    "def clean_example_post(post):\n",
    "    post = re.sub(r'\\s+', ' ', post.strip())  # Clean up whitespace\n",
    "    post = re.sub(r\"[^a-zA-Z0-9,.!?'\\\"]+\", ' ', post)  # Remove garbage characters\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', post)  # Split into sentences\n",
    "\n",
    "    # Priority: suggestions, recommendations, or longer useful text\n",
    "    for s in sentences:\n",
    "        s = s.strip()\n",
    "        if 50 < len(s) < 200 and any(word in s.lower() for word in ['suggest', 'recommend', 'quality', 'bought', 'used']):\n",
    "            return s\n",
    "\n",
    "    # Fallback to first readable sentence\n",
    "    for s in sentences:\n",
    "        if 40 < len(s) < 200:\n",
    "            return s\n",
    "\n",
    "    return post[:140] + \"...\"\n",
    "\n",
    "# 6. Generate Dashboard-Ready Summary\n",
    "def generate_user_friendly_summary(topic_id, keywords, sentiment_counts, example_posts=None):\n",
    "    pos = sentiment_counts.get(\"POSITIVE\", 0)\n",
    "    neg = sentiment_counts.get(\"NEGATIVE\", 0)\n",
    "    sug = sentiment_counts.get(\"SUGGESTION\", 0)\n",
    "    total = pos + neg + sug\n",
    "    if total == 0:\n",
    "        return None\n",
    "\n",
    "    if neg > pos and neg > sug:\n",
    "        insight = \"âš ï¸ Users are expressing dissatisfaction with this topic.\"\n",
    "    elif sug > pos and sug > neg:\n",
    "        insight = \"ðŸ’¡ Users are sharing a lot of suggestions here.\"\n",
    "    elif pos > neg and pos > sug:\n",
    "        insight = \"âœ… This topic is receiving mostly positive feedback.\"\n",
    "    else:\n",
    "        insight = \"ðŸ“ Mixed feedback observed.\"\n",
    "\n",
    "    return {\n",
    "        \"topic_id\": topic_id,\n",
    "        \"keywords\": keywords,\n",
    "        \"insight\": insight,\n",
    "        \"positive\": pos,\n",
    "        \"negative\": neg,\n",
    "        \"suggestion\": sug,\n",
    "        \"example_posts\": [clean_example_post(post) for post in example_posts[:2]]\n",
    "\n",
    "    }\n",
    "\n",
    "summaries = []\n",
    "for topic_id, topic_info in topics:\n",
    "    keywords = clean_lda_keywords_with_pos(topic_info)\n",
    "    sentiment_counts = topic_sentiment_counts.get(topic_id, {})\n",
    "    example_posts = topic_to_posts.get(topic_id, [])\n",
    "    summary = generate_user_friendly_summary(topic_id, keywords, sentiment_counts, example_posts[:2] )\n",
    "    if summary:\n",
    "        summaries.append(summary)\n",
    "print(summaries)\n",
    "# 7. Hebbian Learning (optional scoring)\n",
    "topic_strs = [t[1] for t in topics]\n",
    "hebbian = HebbianLearning(topic_strs)\n",
    "for res in sentiments:\n",
    "    score = res['score'] if res['label'] == \"positive\" else -res['score']\n",
    "    for topic in topic_strs:\n",
    "        hebbian.update(topic, score)\n",
    "print(\"\\nHebbian Associations:\")\n",
    "for topic, assoc in hebbian.get_associations().items():\n",
    "    print(f\"{topic}: {assoc:.4f}\")\n",
    "\n",
    "# 8. SOM Clustering\n",
    "senti_vectors = []\n",
    "for res in sentiments:\n",
    "    if res['label'] == \"positive\":\n",
    "        senti_vectors.append([res['score'], 0.0, 0.0])\n",
    "    elif res['label'] == \"negative\":\n",
    "        senti_vectors.append([0.0, res['score'], 0.0])\n",
    "    else:\n",
    "        senti_vectors.append([0.0, 0.0, res['score']])\n",
    "clusters = cluster_sentiments(senti_vectors)\n",
    "print(\"\\nSOM Clusters:\")\n",
    "print(clusters)\n",
    "\n",
    "# 9. Per-Organization Sentiment Breakdown\n",
    "org_sentiment_distribution = compute_sentiment_breakdown_per_org(cleaned_posts, sentiments, brands_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf04f4a6-ef06-4d79-a55d-8b4f8b10159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize suggestions method\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def summarize_suggestions(suggestions_by_org, num_summary_sentences=3):\n",
    "    summary_by_org = {}\n",
    "    for org, suggestions in suggestions_by_org.items():\n",
    "        if not suggestions:\n",
    "            continue\n",
    "        clean_suggestions = [re.sub(r'\\s+', ' ', s.strip()) for s in suggestions]\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        X = vectorizer.fit_transform(clean_suggestions)\n",
    "        n_clusters = min(3, len(clean_suggestions))\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(X)\n",
    "        summary = []\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = (kmeans.labels_ == i).nonzero()[0]\n",
    "            if len(cluster_indices) > 0:\n",
    "                first_comment = clean_suggestions[cluster_indices[0]]\n",
    "                summary.append(first_comment)\n",
    "        summary_by_org[org] = summary[:num_summary_sentences]\n",
    "    return summary_by_org\n",
    "    \n",
    "def get_lda_topics_per_org(suggestions_by_org):\n",
    "    org_topics = {}\n",
    "    for org, suggestions in suggestions_by_org.items():\n",
    "        if len(suggestions) < 3:\n",
    "            continue\n",
    "        tokenized = [word_tokenize(clean_text(s)) for s in suggestions]\n",
    "        dictionary = corpora.Dictionary(tokenized)\n",
    "        corpus = [dictionary.doc2bow(text) for text in tokenized]\n",
    "        lda_model = LdaMulticore(corpus, num_topics=2, id2word=dictionary, passes=5, workers=1)\n",
    "        topics = lda_model.print_topics(num_words=4)\n",
    "        org_topics[org] = topics\n",
    "    return org_topics\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def assign_clusters_to_orgs(brands_products, clusters):\n",
    "    org_clusters = defaultdict(list)\n",
    "\n",
    "    for i, entities in enumerate(brands_products):\n",
    "        for entity, ent_type in entities:\n",
    "            if ent_type == \"ORG\":\n",
    "                org_clusters[entity].append(clusters[i])\n",
    "\n",
    "    return org_clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f78815e7-4d73-481a-9eac-dc641dc0cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#Sentiment Breakdown per SOM Cluster \n",
    "def sentiment_breakdown_per_som_cluster(clusters, sentiments):\n",
    "    cluster_stats = defaultdict(lambda: {\"POSITIVE\": 0, \"NEGATIVE\": 0, \"SUGGESTION\": 0})\n",
    "    for clust, sent in zip(clusters, sentiments):\n",
    "        label = sent[\"label\"]\n",
    "        cluster_stats[clust][label] += 1\n",
    "    return cluster_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "700d3600-6223-485b-89a4-ee6c8f62312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Suggestions by Organization:\n",
      "{}\n",
      "\n",
      "Summary of Suggestions by Organization:\n",
      "\n",
      "LDA Topics Per Organization:\n",
      "\n",
      "Sentiment Breakdown Per SOM Cluster:\n",
      "Cluster (2, 1):\n",
      "  POSITIVE: 2\n",
      "  NEGATIVE: 3\n",
      "  SUGGESTION: 2\n",
      "Cluster (0, 0):\n",
      "  POSITIVE: 0\n",
      "  NEGATIVE: 3\n",
      "  SUGGESTION: 2\n",
      "Cluster (0, 2):\n",
      "  POSITIVE: 0\n",
      "  NEGATIVE: 0\n",
      "  SUGGESTION: 4\n",
      "Cluster (1, 1):\n",
      "  POSITIVE: 1\n",
      "  NEGATIVE: 4\n",
      "  SUGGESTION: 3\n",
      "Cluster (0, 1):\n",
      "  POSITIVE: 0\n",
      "  NEGATIVE: 1\n",
      "  SUGGESTION: 4\n",
      "Cluster (2, 2):\n",
      "  POSITIVE: 1\n",
      "  NEGATIVE: 1\n",
      "  SUGGESTION: 3\n",
      "Cluster (2, 0):\n",
      "  POSITIVE: 4\n",
      "  NEGATIVE: 1\n",
      "  SUGGESTION: 1\n",
      "Cluster (1, 2):\n",
      "  POSITIVE: 0\n",
      "  NEGATIVE: 1\n",
      "  SUGGESTION: 4\n",
      "Cluster (1, 0):\n",
      "  POSITIVE: 1\n",
      "  NEGATIVE: 2\n",
      "  SUGGESTION: 2\n",
      "\n",
      "Buyitforlife Canada:\n",
      "  Cluster (2, 1): 1 posts\n",
      "\n",
      "Lennon Uk:\n",
      "  Cluster (2, 1): 1 posts\n",
      "\n",
      "Cookware Solidteknics Aus:\n",
      "  Cluster (2, 1): 1 posts\n",
      "\n",
      "Tempur:\n",
      "  Cluster (0, 2): 1 posts\n",
      "\n",
      "Recs Mobile:\n",
      "  Cluster (1, 2): 1 posts\n",
      "\n",
      "Arena Speedo:\n",
      "  Cluster (1, 2): 1 posts\n",
      "\n",
      "Demeyre De Buyer:\n",
      "  Cluster (1, 1): 1 posts\n",
      "\n",
      "Slip Steel:\n",
      "  Cluster (0, 1): 1 posts\n"
     ]
    }
   ],
   "source": [
    "# --- Suggestions Per Organization ---\n",
    "suggestions_by_org = get_suggestions_by_org(cleaned_posts, sentiments, brands_products)\n",
    "org_topics = get_lda_topics_per_org(suggestions_by_org)\n",
    "cluster_sentiments_list = sentiment_breakdown_per_som_cluster(clusters, sentiments)\n",
    "\n",
    "\n",
    "print(\"\\nSuggestions by Organization:\")\n",
    "for org, suggestions in suggestions_by_org.items():\n",
    "    print(f\"\\n{org}:\")\n",
    "    for s in suggestions:\n",
    "        print(f\"  - {s}\")\n",
    "        \n",
    "summarized = summarize_suggestions(suggestions_by_org)\n",
    "print(summarized)\n",
    "print(\"\\nSummary of Suggestions by Organization:\")\n",
    "for org, summaries in summarized.items():\n",
    "    print(f\"\\n{org}:\")\n",
    "    for s in summaries:\n",
    "        print(f\"  - {s}\")\n",
    "        \n",
    "print(\"\\nLDA Topics Per Organization:\")\n",
    "for org, topics in org_topics.items():\n",
    "    print(f\"\\n{org}:\")\n",
    "    for topic in topics:\n",
    "        print(f\"  - {topic}\")\n",
    "        \n",
    "print(\"\\nSentiment Breakdown Per SOM Cluster:\")\n",
    "for cluster, breakdown in cluster_sentiments_list.items():\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    for label, count in breakdown.items():\n",
    "        print(f\"  {label}: {count}\")\n",
    "\n",
    "org_clusters = assign_clusters_to_orgs(brands_products, clusters)\n",
    "\n",
    "# Display per-organization cluster assignments\n",
    "for org, cluster_list in org_clusters.items():\n",
    "    print(f\"\\n{org}:\")\n",
    "    counts = defaultdict(int)\n",
    "    for cl in cluster_list:\n",
    "        counts[cl] += 1\n",
    "    for cluster, count in counts.items():\n",
    "        print(f\"  Cluster {cluster}: {count} posts\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4bbc861-cb31-4eec-8c0f-6e0576fdb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_lda_coherence(lda_model, tokenized_posts, dictionary):\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=tokenized_posts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print(f\"LDA Coherence Score: {coherence_score:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(['LDA Topic Modeling'], [coherence_score], color='cornflowerblue')\n",
    "    plt.ylabel(\"Coherence Score (c_v)\")\n",
    "    plt.title(\"LDA Coherence Score\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return coherence_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b73335-278e-47de-a9a6-43782372755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# # Load your trained model\n",
    "# sentiment_pipeline = pipeline(\"text-classification\", model=\"./bert-multiclass-model\", tokenizer=\"./bert-multiclass-model\")\n",
    "\n",
    "# def analyze_sentiments(texts):\n",
    "#     sentiments = []\n",
    "#     for text in texts:\n",
    "#         result = sentiment_pipeline(text)[0]  # e.g., {'label': 'LABEL_2', 'score': 0.92}\n",
    "#         label = result['label']\n",
    "#         label_map = {'LABEL_0': 'POSITIVE', 'LABEL_1': 'NEGATIVE', 'LABEL_2': 'SUGGESTION'}\n",
    "#         sentiments.append({'label': label_map[label], 'score': result['score']})\n",
    "#     return sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7667eb38-ee9d-41a1-a1fa-cb47dc4156fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Coherence Score: 0.5005\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOM Silhouette Score: 0.6311\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda_score = visualize_lda_coherence(lda_model, tokenized_posts, dictionary)\n",
    "som_score = visualize_som_silhouette(senti_vectors, clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd0692-4549-430a-88d8-f2b4319d0f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
